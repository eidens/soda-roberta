version: '2.3'

services:
  nlp: &nlp
    build:
      context: ./src
      dockerfile: '../Dockerfile-mac'
    image: sdbert
    volumes:
    - ./src:/app
    - ./data:/data
    - ./tokenizer:/tokenizer
    - ./lm_models:/lm_models
    - ./tokcl_models:/tokcl_models
    - ./cache:/cache
    env_file:
    - ./.env
    ipc: host
    tty: true
    stdin_open: true
    working_dir: /app

  tensorboard:
    build:
      context: ./src
      dockerfile: '../Dockerfile-mac'
    depends_on:
    - nlp
    ports:
    - 6007:6007
    volumes:
    - ./runs:/runs
    working_dir: /app
    command: tensorboard --logdir /runs --port 6007 # --bind_all

  celery:
    build:
      context: ./src
      dockerfile: '../Dockerfile-mac'
    depends_on:
    - rabbitmq
    volumes:
    - ./src:/app
    - ./data:/data
    - ./tokenizer:/tokenizer
    - ./lm_models:/lm_models
    - ./tokcl_models:/tokcl_models
    - ./cache:/cache
    env_file:
    - ./.env
    working_dir: /app
    command: celery --app=lm worker --loglevel=info

  flower:
    build:
      context: ./src
      dockerfile: '../Dockerfile-mac'
    depends_on:
    - celery
    ports:
      - "5555:5555"
    working_dir: /app/src
    command: flower --app=lm --port=5555 --broker=rabbitmq

  rabbitmq:
    image: rabbitmq:3-management
    ports:
      # The standard AMQP protocol port
      - '5672:5672'
      # HTTP management UI at http://localhost:15672/
      - '15672:15672'
