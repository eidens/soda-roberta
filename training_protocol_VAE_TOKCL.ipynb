{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(vocab_siz=54000, max_length=128, truncation=True, min_char_length=120, split_ratio={'train': 0.7, 'eval': 0.2, 'test': 0.1, 'max_eval': 10000, 'max_test': 10000}, celery_batch_size=1000, from_pretrained='facebook/bart-base', model_type='GraphRepresentation', tokenizer=PreTrainedTokenizerFast(name_or_path='facebook/bart-base', vocab_size=50265, model_max_len=1024, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)}), nlp=<spacy.lang.en.English object at 0x7f0befcdd940>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smtag.config import config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting examples for TOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.extract import ExtractorXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"/data/xml/191012\"\n",
    "xml_examples = \"/data/text/sd_test\"\n",
    "xpath = \".//sd-panel\"\n",
    "sentence_level = False\n",
    "keep_xml = True\n",
    "inclusion_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr /data/text/sd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/text/sd_test created\n"
     ]
    }
   ],
   "source": [
    "extractor_tokcl = ExtractorXML(\n",
    "    corpus,\n",
    "    destination_dir=xml_examples,\n",
    "    sentence_level=sentence_level,\n",
    "    xpath=xpath,\n",
    "    keep_xml=keep_xml,\n",
    "    inclusion_probability=inclusion_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:24<00:00, 24.03s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.44s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/data/text/sd_test/train.txt'): 15859,\n",
       " PosixPath('/data/text/sd_test/eval.txt'): 4869,\n",
       " PosixPath('/data/text/sd_test/test.txt'): 2399}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_tokcl.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same via CLI:\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/191012/ /data/text/sd_test --xpath \".//sd-panel\" --sentence_level --keep_xml --inclusion_probability 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing tokenized dataset for VAE TOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.dataprep import PreparatorTOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.xml2labels import SourceDataCodes as sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr /data/json/sd_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examples = \"/data/json/sd_test\"\n",
    "code_maps: code_maps = [\n",
    "    sd.ENTITY_TYPES,\n",
    "    sd.GENEPROD_ROLES,\n",
    "    sd.BORING,\n",
    "    sd.PANELIZATION\n",
    "]\n",
    "max_length = config.max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/json/sd_test created\n"
     ]
    }
   ],
   "source": [
    "prep_tokcl = PreparatorTOKCL(\n",
    "    xml_examples,\n",
    "    tokenized_examples,\n",
    "    code_maps,\n",
    "    max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 1292/15859 [00:02<00:31, 464.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 274 in 'lation of >>>mitochondria^l...<<<ow cells. '\n",
      "WARNING: token overlaps element boundary sd-tag at position 310 in 'entage of >>>mitochondria^l...<<<ow cells/S'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1451/15859 [00:03<00:28, 503.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 12 in 'hanges in >>>H^D...<<<X behavior'\n",
      "WARNING: token overlaps element boundary sd-tag at position 358 in 'tion. All >>>H^D...<<<X MS data '\n",
      "WARNING: token overlaps element boundary sd-tag at position 457 in 'f GMPPCP. >>>H^D...<<<X data are'\n",
      "WARNING: token overlaps element boundary sd-tag at position 179 in 'crease in >>>H^D...<<<X. Quantit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2041/15859 [00:04<00:25, 543.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 48 in 'alysis of >>>EC^B...<<<rdU incorp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 2317/15859 [00:04<00:27, 488.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 109 in '−folate + >>>A^G...<<<CT (n = 75'\n",
      "WARNING: token overlaps element boundary sd-tag at position 111 in 'olate + AG>>>C^T...<<< (n = 75).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 5644/15859 [00:11<00:21, 482.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 14 in ') Braf-/-;>>>ER^T...<<<mHRasG12V '\n",
      "WARNING: token overlaps element boundary sd-tag at position 14 in ') Braf-/-;>>>ER^T...<<<mHRasG12V '\n",
      "WARNING: token overlaps element boundary sd-tag at position 19 in ': Braf-/-;>>>ER^T...<<<mHRasG12V '\n",
      "WARNING: token overlaps element boundary sd-tag at position 19 in ': Braf-/-;>>>ER^T...<<<mHRasG12V '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 6127/15859 [00:12<00:21, 458.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 257 in ' (E), the >>>neuron^s...<<< were anal'\n",
      "WARNING: token overlaps element boundary sd-tag at position 257 in ' (E), the >>>neuron^s...<<< were anal'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 7785/15859 [00:16<00:14, 543.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 74 in 'red in S(->>>N^C...<<<) for 4 h '\n",
      "WARNING: token overlaps element boundary sd-tag at position 74 in 'red in S(->>>N^C...<<<) for 4 h '\n",
      "WARNING: token overlaps element boundary sd-tag at position 37 in 'red in S(->>>N^C...<<<) for 4 h.'\n",
      "WARNING: token overlaps element boundary sd-tag at position 37 in 'red in S(->>>N^C...<<<) for 4 h.'\n",
      "WARNING: token overlaps element boundary sd-tag at position 5 in '>>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 5 in '>>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 284 in 'e mutated >>>T^Y...<<<88A allele'\n",
      "WARNING: token overlaps element boundary sd-tag at position 284 in 'e mutated >>>T^Y...<<<88A allele'\n",
      "WARNING: token overlaps element boundary sd-tag at position 128 in 'nt in the >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 128 in 'nt in the >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 22 in 'alysis of >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 315 in 'enance in >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 341 in 'mpared to >>>T^W...<<<T controls'\n",
      "WARNING: token overlaps element boundary sd-tag at position 22 in 'alysis of >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 315 in 'enance in >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 341 in 'mpared to >>>T^W...<<<T controls'\n",
      "WARNING: token overlaps element boundary sd-tag at position 120 in ' FACS, in >>>T^W...<<<T-, TY88A-'\n",
      "WARNING: token overlaps element boundary sd-tag at position 126 in ' in TWT-, >>>T^Y...<<<88A-, and '\n",
      "WARNING: token overlaps element boundary sd-tag at position 120 in ' FACS, in >>>T^W...<<<T-, TY88A-'\n",
      "WARNING: token overlaps element boundary sd-tag at position 126 in ' in TWT-, >>>T^Y...<<<88A-, and '\n",
      "WARNING: token overlaps element boundary sd-tag at position 75 in 'm control >>>T^W...<<<T and TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 83 in 'l TWT and >>>T^Y...<<<88A during'\n",
      "WARNING: token overlaps element boundary sd-tag at position 75 in 'm control >>>T^W...<<<T and TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 83 in 'l TWT and >>>T^Y...<<<88A during'\n",
      "WARNING: token overlaps element boundary sd-tag at position 33 in 'ession in >>>T^W...<<<T- and TY8'\n",
      "WARNING: token overlaps element boundary sd-tag at position 42 in ' TWT- and >>>T^Y...<<<88A-Tg(TmC'\n",
      "WARNING: token overlaps element boundary sd-tag at position 33 in 'ession in >>>T^W...<<<T- and TY8'\n",
      "WARNING: token overlaps element boundary sd-tag at position 42 in ' TWT- and >>>T^Y...<<<88A-Tg(TmC'\n",
      "WARNING: token overlaps element boundary sd-tag at position 95 in 'mpared to >>>T^W...<<<T) in TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 103 in 'o TWT) in >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 95 in 'mpared to >>>T^W...<<<T) in TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 103 in 'o TWT) in >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 46 in 'alysis of >>>T^W...<<<T- and TY8'\n",
      "WARNING: token overlaps element boundary sd-tag at position 55 in ' TWT- and >>>T^Y...<<<88A-Tg(TmC'\n",
      "WARNING: token overlaps element boundary sd-tag at position 46 in 'alysis of >>>T^W...<<<T- and TY8'\n",
      "WARNING: token overlaps element boundary sd-tag at position 55 in ' TWT- and >>>T^Y...<<<88A-Tg(TmC'\n",
      "WARNING: token overlaps element boundary sd-tag at position 101 in 'e box, in >>>T^W...<<<T and TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 109 in 'n TWT and >>>T^Y...<<<88A in vit'\n",
      "WARNING: token overlaps element boundary sd-tag at position 101 in 'e box, in >>>T^W...<<<T and TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 109 in 'n TWT and >>>T^Y...<<<88A in vit'\n",
      "WARNING: token overlaps element boundary sd-tag at position 122 in 'opment in >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 122 in 'opment in >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 81 in ' of E8.25 >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 107 in 'mpared to >>>T^W...<<<T control.'\n",
      "WARNING: token overlaps element boundary sd-tag at position 81 in ' of E8.25 >>>T^Y...<<<88A mutant'\n",
      "WARNING: token overlaps element boundary sd-tag at position 107 in 'mpared to >>>T^W...<<<T control.'\n",
      "WARNING: token overlaps element boundary sd-tag at position 41 in 'ession in >>>T^Y...<<<88A compar'\n",
      "WARNING: token overlaps element boundary sd-tag at position 59 in 'mpared to >>>T^W...<<<T control '\n",
      "WARNING: token overlaps element boundary sd-tag at position 203 in 'ession in >>>T^Y...<<<88A compar'\n",
      "WARNING: token overlaps element boundary sd-tag at position 221 in 'mpared to >>>T^W...<<<T control '\n",
      "WARNING: token overlaps element boundary sd-tag at position 41 in 'ession in >>>T^Y...<<<88A compar'\n",
      "WARNING: token overlaps element boundary sd-tag at position 59 in 'mpared to >>>T^W...<<<T control '\n",
      "WARNING: token overlaps element boundary sd-tag at position 203 in 'ession in >>>T^Y...<<<88A compar'\n",
      "WARNING: token overlaps element boundary sd-tag at position 221 in 'mpared to >>>T^W...<<<T control '\n",
      "WARNING: token overlaps element boundary sd-tag at position 59 in 'bodies of >>>T^W...<<<T and TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 67 in 'f TWT and >>>T^Y...<<<88A mESCs.'\n",
      "WARNING: token overlaps element boundary sd-tag at position 59 in 'bodies of >>>T^W...<<<T and TY88'\n",
      "WARNING: token overlaps element boundary sd-tag at position 67 in 'f TWT and >>>T^Y...<<<88A mESCs.'\n",
      "WARNING: token overlaps element boundary sd-tag at position 65 in 'mpared to >>>T^W...<<<T at day 4'\n",
      "WARNING: token overlaps element boundary sd-tag at position 65 in 'mpared to >>>T^W...<<<T at day 4'\n",
      "WARNING: token overlaps element boundary sd-tag at position 62 in 'n control >>>T^W...<<<T compared'\n",
      "WARNING: token overlaps element boundary sd-tag at position 62 in 'n control >>>T^W...<<<T compared'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 9350/15859 [00:19<00:13, 486.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 176 in 'bivalent (>>>X^Y...<<<) and thei'\n",
      "WARNING: token overlaps element boundary sd-tag at position 272 in 'bivalent (>>>X^Y...<<<) is indic'\n",
      "WARNING: token overlaps element boundary sd-tag at position 32 in 'cation of >>>mitochondria^l...<<< numbers f'\n",
      "WARNING: token overlaps element boundary sd-tag at position 32 in 'cation of >>>mitochondria^l...<<< numbers f'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 15108/15859 [00:31<00:01, 434.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 49 in '1-Lmo2+nu/>>>nu^m...<<<ice (green'\n",
      "WARNING: token overlaps element boundary sd-tag at position 49 in '1-Lmo2+nu/>>>nu^m...<<<ice (green'\n",
      "WARNING: token overlaps element boundary sd-tag at position 58 in '1-Lmo2+nu/>>>nu^m...<<<ice studie'\n",
      "WARNING: token overlaps element boundary sd-tag at position 237 in 'ermate nu/>>>nu^m...<<<ouse is sh'\n",
      "WARNING: token overlaps element boundary sd-tag at position 58 in '1-Lmo2+nu/>>>nu^m...<<<ice studie'\n",
      "WARNING: token overlaps element boundary sd-tag at position 237 in 'ermate nu/>>>nu^m...<<<ouse is sh'\n",
      "WARNING: token overlaps element boundary sd-tag at position 66 in '1-Lmo2+nu/>>>nu^m...<<<ouse. A co'\n",
      "WARNING: token overlaps element boundary sd-tag at position 99 in 'ermate nu/>>>nu^m...<<<ouse is sh'\n",
      "WARNING: token overlaps element boundary sd-tag at position 66 in '1-Lmo2+nu/>>>nu^m...<<<ouse. A co'\n",
      "WARNING: token overlaps element boundary sd-tag at position 99 in 'ermate nu/>>>nu^m...<<<ouse is sh'\n",
      "WARNING: token overlaps element boundary sd-tag at position 53 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 121 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 53 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 121 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 70 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 134 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 70 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 134 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15859/15859 [00:32<00:00, 480.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 91 (min=24, max=128) tokens\n",
      "longest example: <s>Knockdown of components of the BRM complex reduces Su(H) recruitment both in Notch-OFF (B) and Notch-ON (C) conditions. Fold enrichment of Su(H) occupancy at the indicated positions detected by ChIP, relative to input, in Kc167 cells treated with brm, Snr1 or GFP RNAi as a control. Notch-ON conditions (C) were induced by 30 minutes of EGTA treatment. Mean +/- SEM, n = 3 (B); Mean, n = 2 (C); * p<0.05 with one-tailed student's</s>\n",
      "shortest example: <s>E Ten-fold serial dilutions and subsequent colony formation of the indicated mutant cells at the indicated temperatures. </s>\n",
      "Preparing: eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 433/4869 [00:00<00:08, 513.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 338 in ' (green). >>>Cre^st...<<<aining (re'\n",
      "WARNING: token overlaps element boundary sd-tag at position 338 in ' (green). >>>Cre^st...<<<aining (re'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 2677/4869 [00:05<00:04, 526.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 110 in 'in VM and >>>AM^C...<<<Ms.Data in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4869/4869 [00:09<00:00, 487.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 88 (min=26, max=128) tokens\n",
      "longest example: <s>(F) Bar graphs showing the mean velocity and the mean run length of processive DDB events for the three Lis1 conditions (as in A, B and C). Error bars are the s.e.m. Mean velocities were 0.37 ± 0.02 µm/s (A), 0.38 ± 0.03 µm/s (B), and 0.35 ± 0.03 µm/s (C). Mean run lengths were 3.1 ± 0.4 µm (A), 3.2 ± 0.5 µm (B), and 2.9 ±</s>\n",
      "shortest example: <s>Number of soft agar colonies (n=3 independent experiments formed by Rat2 cells stably expressing the indicated constructs </s>\n",
      "Preparing: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2399/2399 [00:05<00:00, 466.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 90 (min=26, max=128) tokens\n",
      "longest example: <s>C and D, Motoneuron defects induced in zebrafish embryos after expression of the indicated ALS-linked PDI mutants and wild-type controls (PDIA1WT and PDIA1R300H: 80 pg mRNA/embryo; ERp57WT, ERp57D217N, ERp57D217N and ERp57Q481K: 30 pgtba mRNA/embryo). The most frequent global phenotypes induced by PDI injection are shown in lateral views of embryos at 24 hpf (left column). Black arrows indicate the presence of curly tail and/or shorter axis</s>\n",
      "shortest example: <s>B. Indicated stable RPE clones in densely cultured conditions were analyzed by Western blotting for the indicated proteins. </s>\n"
     ]
    }
   ],
   "source": [
    "prep_tokcl.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same vie CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.tokcl.dataprep /data/text/sd_test /data/json/sd_test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE model for TOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.train.train_tokcl import (\n",
    "    train as train_tokcl,\n",
    "    TrainingArgumentsTOKCL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsTOKCL(output_dir='/tokcl_models', overwrite_output_dir=True, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/tokcl_models/runs/Feb12_23-19-41_ff6b0b617c42', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=100, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name='/tokcl_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', masking_probability=0.0, replacement_probability=0.0, select_labels=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_tokcl = TrainingArgumentsTOKCL(\n",
    "    num_train_epochs=5,\n",
    "    logging_steps=100,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    replacement_probability=.0,\n",
    "    masking_probability=.0\n",
    ")\n",
    "training_args_tokcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cache = True\n",
    "loader_path = \"./smtag/loader/loader_tokcl.py\"\n",
    "data_config_name =  \"NER\"\n",
    "tokenizer = config.tokenizer\n",
    "model_type = \"GraphRepresentation\"\n",
    "from_pretrained = \"facebook/bart-base\"  # specialized model from huggingface.co/embo #  \"roberta-base\" # general lm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/datasets/load.py:1650: FutureWarning: 'script_version' was renamed to 'revision' in version 1.13 and will be removed in 1.15.\n",
      "  warnings.warn(\n",
      "WARNING:Using custom data configuration NER-e90bf469e54b0531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading and tokenizing datasets found in /data/json/sd_test.\n",
      "using ./smtag/loader/loader_tokcl.py as dataset loader.\n",
      "Downloading and preparing dataset source_data_nlp/NER to /cache/source_data_nlp/NER-e90bf469e54b0531/0.0.1/c48c223ec09c8e1fd9e2312185ea3720f8c653a7c58323168790637ebb931f03...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'special_tokens_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ab30697f7c84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_tokcl(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtraining_args_tokcl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloader_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_config_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenized_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/train/train_tokcl.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_args, loader_path, data_config_name, data_dir, no_cache, tokenizer, model_type, from_pretrained)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nLoading and tokenizing datasets found in {data_dir}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"using {loader_path} as dataset loader.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     train_dataset, eval_dataset, test_dataset = load_dataset(\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloader_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_config_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/load.py\u001b[0m in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, script_version, **config_kwargs)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[0;31m# Download and prepare data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m     builder_instance.download_and_prepare(\n\u001b[0m\u001b[1;32m   1695\u001b[0m         \u001b[0mdownload_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m         \u001b[0mdownload_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdownload_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36mdownload_and_prepare\u001b[0;34m(self, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    593\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"HF google storage unreachable. Downloading and preparing it from source\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdownloaded_from_gcs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                         self._download_and_prepare(\n\u001b[0m\u001b[1;32m    596\u001b[0m                             \u001b[0mdl_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdl_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_infos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_infos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdownload_and_prepare_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_download_and_prepare\u001b[0;34m(self, dl_manager, verify_infos, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 \u001b[0;31m# Prepare split will record examples associated to the split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 683\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mprepare_split_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    684\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                 raise OSError(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m_prepare_split\u001b[0;34m(self, split_generator)\u001b[0m\n\u001b[1;32m   1080\u001b[0m                     \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_verbosity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTSET\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                 ):\n\u001b[0;32m-> 1082\u001b[0;31m                     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_example\u001b[0;34m(self, example)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \"\"\"\n\u001b[1;32m   1098\u001b[0m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_python_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mencode_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36mencode_nested_example\u001b[0;34m(schema, obj)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;31m# Nested structures: we allow dict, list/tuples, sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         return {\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         }\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/features/features.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[0;31m# Nested structures: we allow dict, list/tuples, sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         return {\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mencode_nested_example\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msub_schema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_obj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzip_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m         }\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36mzip_dict\u001b[0;34m(*dicts)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# set merge all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/datasets/utils/py_utils.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# set merge all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m# Will raise KeyError if the dict don't have the same keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'special_tokens_mask'"
     ]
    }
   ],
   "source": [
    "train_tokcl(\n",
    "    training_args_tokcl,\n",
    "    loader_path,\n",
    "    data_config_name,\n",
    "    tokenized_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "same via CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.tokcl.train \\\n",
    "./smtag/loader/loader_tokcl.py NER \\\n",
    "--data_dir /data/json/sd_test \\\n",
    "--num_train_epochs=20 --logging_steps=100 \\\n",
    "--per_device_train_batch_size=16 \\\n",
    "--per_device_eval_batch_size=16 \\\n",
    "--replacement_probability=.0 \\\n",
    "--masking_probability=.0 \\\n",
    "--model_type=\"GraphRepresentation\" \\\n",
    "--from_pretrained=\"facebook/bart-base\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
